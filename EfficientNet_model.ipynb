{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b8a4fe8-8566-4972-bc5e-c5f2864f0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "57f2498c-78f7-433f-b547-d77f461a9f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1b4a06f-b9bc-4be5-a62e-9c773be67748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2748, Validation: 589, Test: 589\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/train_images.csv\")\n",
    "train_data['image_path'] = 'data' + train_data['image_path']\n",
    "\n",
    "train_df, temp_df = train_test_split(train_data, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ec9c464-19dd-40fb-bc03-84e0d31a2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdieDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.data.iloc[index, 0])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        # 0-based indexing\n",
    "        label = int(self.data.iloc[index, 1]) - 1  \n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da71587e-832e-49cf-8daa-f6bc1726147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38f2e4a2-0ff0-42fd-8d70-aa6dd3f144ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BirdieDataset(train_df, root_dir=\"\", transform=train_transform)\n",
    "val_dataset = BirdieDataset(val_df, root_dir=\"\", transform=val_test_transform)\n",
    "test_dataset = BirdieDataset(test_df, root_dir=\"\", transform=val_test_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2fbbe41a-968a-4a73-a3f4-0de16e7582db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meryjoy/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/meryjoy/opt/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 200) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b10bb775-5e07-41f6-994e-b77966cbdaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c4d52315-2763-471c-8a7e-64b420aa6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100. * correct / total\n",
    "        val_acc = evaluate_model(model, val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {running_loss:.4f} - Train Acc: {train_acc:.2f}% - Val Acc: {val_acc:.2f}%\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    print(\"Training Complete. Best Validation Accuracy:\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "224b9c3f-d132-4cbd-a039-a27acfb903be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [12:58<00:00,  9.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 444.0411 - Train Acc: 2.73% - Val Acc: 9.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [12:24<00:00,  8.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Loss: 389.3887 - Train Acc: 18.74% - Val Acc: 19.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [11:32<00:00,  8.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Loss: 322.3734 - Train Acc: 32.57% - Val Acc: 29.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [12:03<00:00,  8.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Loss: 265.7648 - Train Acc: 42.36% - Val Acc: 35.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [12:05<00:00,  8.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Loss: 218.4249 - Train Acc: 51.31% - Val Acc: 41.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [11:40<00:00,  8.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Loss: 182.2168 - Train Acc: 59.02% - Val Acc: 43.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [11:25<00:00,  7.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Loss: 151.4660 - Train Acc: 66.78% - Val Acc: 48.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [12:00<00:00,  8.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Loss: 127.5468 - Train Acc: 72.53% - Val Acc: 52.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [12:56<00:00,  9.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Loss: 108.3412 - Train Acc: 77.91% - Val Acc: 52.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 86/86 [12:16<00:00,  8.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Loss: 89.5271 - Train Acc: 83.30% - Val Acc: 54.50%\n",
      "Training Complete. Best Validation Accuracy: 54.49915110356537\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return 100. * correct / total\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37d6c3a5-1b30-4c27-b0f6-520e184a363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./data/test_images_path.csv\")\n",
    "class_names = []\n",
    "for name in np.load(\"./data/class_names.npy\", allow_pickle=True).item():\n",
    "    class_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4297087f-868c-41d9-9156-a9d3c5f525fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "# Predict labels for all test images\n",
    "for _, row in test_data.iterrows():\n",
    "    image_path = f\"./data/{row['image_path']}\"  # Construct the full path to the image\n",
    "\n",
    "    # Open and preprocess the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = val_test_transform(image).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
    "\n",
    "    # Predict using the model\n",
    "    output = model(input_tensor)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    # Map predicted class index to class name\n",
    "    predicted_label = class_names[predicted_class.item()]\n",
    "    predictions.append(predicted_label)\n",
    "\n",
    "# Save predictions to a new CSV file\n",
    "test_data[\"predicted_label\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "085605d6-2127-418b-ad92-4ef96e9d7bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6f/_m3vtyy92m94t_l4qyl157240000gn/T/ipykernel_4083/2011218876.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission['label'] = [string[0:3] for string in submission['predicted_label']]\n",
      "/var/folders/6f/_m3vtyy92m94t_l4qyl157240000gn/T/ipykernel_4083/2011218876.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission['label'] = pd.to_numeric(submission['label'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "id         \n",
       "1        67\n",
       "2        39\n",
       "3        74\n",
       "4        12\n",
       "5        74\n",
       "...     ...\n",
       "3996    114\n",
       "3997     95\n",
       "3998    135\n",
       "3999     62\n",
       "4000    111\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = test_data[['id', 'predicted_label']]\n",
    "submission['label'] = [string[0:3] for string in submission['predicted_label']]\n",
    "submission['label'] = pd.to_numeric(submission['label'])\n",
    "submission = submission[['id','label']]\n",
    "submission.index = pd.Index(range(1, len(submission) + 1))\n",
    "submission.index.name = 'id'\n",
    "submission = submission[['label']] \n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a651454-5e14-4556-8f4c-be392d3b0de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
