{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514d1b8-2b69-4db5-bd15-1a02b5087ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "# Xception is part of the timm library since pretrainedmodels is deprecated\n",
    "from timm import create_model  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d2207-41e4-4f9d-881b-dc12fea55909",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./data/train_images.csv\")\n",
    "train_data['image_path'] = train_data['image_path'].apply(lambda x: x.strip())\n",
    "train_data['image_path'] = 'data/' + train_data['image_path']\n",
    "\n",
    "test_data = pd.read_csv(\"./data/test_images_path.csv\")\n",
    "\n",
    "train_df, val_df = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e8fa7-5bcd-405c-8d55-33b69251b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdieDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.data.iloc[index, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "         # 0-based indexing\n",
    "        label = int(self.data.iloc[index, 1]) - 1 \n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.data['image_path']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d68935-5ba6-4781-8156-a52952ba61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations\n",
    "train_transform = transforms.Compose([\n",
    "    # Xception requires input size 299x299\n",
    "    transforms.Resize((299, 299)),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41c037a-f741-4e07-b39b-14e84e8e99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_dataset = BirdieDataset(train_df, transform=train_transform)\n",
    "val_dataset = BirdieDataset(val_df, transform=test_transform)\n",
    "\n",
    "test_dataset = TestDataset(test_data, transform=test_transform)\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a5d40-e4ec-4d0c-b4e7-a0a64eaf5088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup\n",
    "model = create_model('xception', pretrained=True, num_classes=train_df['label'].nunique())\n",
    "model = model.to(device)\n",
    "\n",
    "# loss, optimizer, and scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# L2 regularization\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a9a10-f548-415e-b72e-5fa05b07d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=5):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_acc = 100. * correct / total\n",
    "        val_acc = evaluate_model(model, val_loader)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), \"best_xception_model.pth\")\n",
    "    print(\"Training complete. Best Validation Accuracy:\", best_acc)\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    return 100. * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0341c-c3fb-4836-aab9-91a99294b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ca2cbf-5b1a-4b71-a2fd-c88c49c7037f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
