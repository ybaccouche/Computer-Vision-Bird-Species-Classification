{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "083acdc4-4c21-45dd-8aa8-0547631e5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet34_Weights\n",
    "import tqdm\n",
    "import time\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353da2df-c233-4004-bdcf-07fe0c3903cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Load CSV data\n",
    "train_df = pd.read_csv(\"./data/train_images.csv\")\n",
    "test_df = pd.read_csv(\"./data/test_images_path.csv\")\n",
    "\n",
    "train_df['image_path'] = 'data' + train_df['image_path']\n",
    "test_df['image_path'] = 'data' + test_df['image_path']\n",
    "\n",
    "# Paths\n",
    "train_dir = \"./data/train_images\"  # Directory for training images\n",
    "test_dir = \"./data/test_images\"    # Directory for test images\n",
    "\n",
    "# Transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.0, 0.0, 0.0), (1.0/255.0, 1.0/255.0, 1.0/255.0))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.0, 0.0, 0.0), (1.0/255.0, 1.0/255.0, 1.0/255.0))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d378b6f-1ecd-4846-876b-269c5b3f71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, transform):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for _, row in df.iterrows():\n",
    "        image = Image.open(row['image_path']).convert(\"RGB\")\n",
    "        image = transform(image)\n",
    "        images.append(image)\n",
    "        labels.append(row['label'] - 1)\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.tensor(labels)\n",
    "    return images, labels\n",
    "\n",
    "train_images, train_labels = prepare_data(train_df, train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ea4346-0cdd-442e-84d4-67208d5ad6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(199)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75a831bc-7909-4efc-a2dc-f5cb71d5b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training and validation sets\n",
    "train_indices, val_indices = train_test_split(range(len(train_images)), test_size=0.2, random_state=42)\n",
    "train_dataset = Subset(TensorDataset(train_images, train_labels), train_indices)\n",
    "val_dataset = Subset(TensorDataset(train_images, train_labels), val_indices)\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b98381f-5ff0-4751-9519-5605041bf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "def train_model(model, criterion, optimizer, scheduler, n_epochs):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    valid_accuracies = []\n",
    "\n",
    "    # set the model to train mode initially\n",
    "    model.train()\n",
    "    for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "        since = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            # get the inputs and assign them to cuda\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calculate the loss/acc later\n",
    "            running_loss += loss.item()\n",
    "            running_correct += (labels==predicted).sum().item()\n",
    "\n",
    "        epoch_duration = time.time() - since\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100.0 / batch_size * running_correct / len(train_loader)\n",
    "        print(\"\\nEpoch %s, duration: %d s, loss: %.4f, acc: %.4f\" % (epoch+1, epoch_duration, epoch_loss, epoch_acc))\n",
    "\n",
    "        losses.append(epoch_loss)\n",
    "        accuracies.append(epoch_acc)\n",
    "\n",
    "        # switch the model to eval mode\n",
    "        model.eval()\n",
    "        valid_acc = eval_model(model)\n",
    "        valid_accuracies.append(valid_acc)\n",
    "\n",
    "        # re-set the model to train mode\n",
    "        model.train()\n",
    "        scheduler.step()\n",
    "        since = time.time()\n",
    "    print('Finished Training')\n",
    "    return model, losses, accuracies, valid_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0e62099-f144-4cbe-abe2-5449e5f586e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation function\n",
    "def eval_model(model):\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    valid_acc = 100.0 * correct / total\n",
    "    print('\\nAccuracy of the network on the valid images: %.4f %%' % (\n",
    "        valid_acc))\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18c765f0-3fbd-4ff5-b723-28a93f27f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "bird_classes = 200\n",
    "model = models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, bird_classes)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# Define the learning rate scheduler\n",
    "lrscheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4ae8c6a-693d-4bdb-9277-41122f886195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, duration: 602 s, loss: 5.1142, acc: 4.7832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 1/5 [10:49<43:16, 649.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the network on the valid images: 11.5776 %\n",
      "\n",
      "Epoch 2, duration: 966 s, loss: 3.9572, acc: 28.5077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 2/5 [27:39<43:05, 861.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the network on the valid images: 25.5725 %\n",
      "\n",
      "Epoch 3, duration: 846 s, loss: 3.1104, acc: 46.1735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [43:23<29:58, 899.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the network on the valid images: 32.9517 %\n",
      "\n",
      "Epoch 4, duration: 1060 s, loss: 2.4800, acc: 59.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▊                | 4/5 [1:01:49<16:20, 980.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the network on the valid images: 37.4046 %\n",
      "\n",
      "Epoch 5, duration: 773 s, loss: 1.9870, acc: 68.0804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [1:16:03<00:00, 912.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the network on the valid images: 43.1298 %\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_trained, losses, accuracies, valid_accuracies = train_model(model, criterion, optimizer, lrscheduler, n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c8bba-3745-44e2-9b51-3ac2377e556d",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuralnetworks]",
   "language": "python",
   "name": "conda-env-neuralnetworks-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
